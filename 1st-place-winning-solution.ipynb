{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Install iterative-stratification**","metadata":{}},{"cell_type":"code","source":"!pip install iterative-stratification","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Import necessary libraries**","metadata":{}},{"cell_type":"code","source":"import optuna\nfrom optuna.samplers import TPESampler\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, classification_report\nfrom sklearn.model_selection import StratifiedKFold,train_test_split\nfrom sklearn.pipeline import Pipeline\n\n# Models\nfrom xgboost import XGBClassifier\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold, RepeatedMultilabelStratifiedKFold\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier, GradientBoostingClassifier","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nimport pandas as pd\nimport numpy as np\nfile_names = []\ndirectory = '/kaggle/input'  \n\nfor dirpath, dirnames, filenames in os.walk(directory):\n    for filename in filenames:\n        file_path = os.path.join(dirpath, filename)\n        file_name = os.path.splitext(os.path.basename(file_path))[0]\n        globals()[file_name] = pd.read_csv(file_path)\n        #print(file_name)\n         \ntrain.drop(columns=[\"id\"],inplace=True)\ntest.drop(columns=[\"id\"],inplace=True)\nmixed_desc.drop(columns=[\"CIDs\"],inplace=True)\ncol=\"EC1_EC2_EC3_EC4_EC5_EC6\"\n\nmixed_desc[col.split(\"_\")]= mixed_desc[col].str.split('_', expand=True).astype(int)\nmixed_desc.drop(col, axis=1, inplace=True)\n\noriginal = mixed_desc[train.columns]\n\ntrain = pd.concat([train,original]).reset_index(drop=True)\ntrain.drop(columns=col.split(\"_\")[2:],inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Gaussian mixture for clustering and density estimation**","metadata":{}},{"cell_type":"code","source":"from sklearn.mixture import GaussianMixture\ndef  get_gmm_class_feature(feat,n):\n    gmm=GaussianMixture(n_components=n,random_state=42)\n    gmm.fit(train[feat].values.reshape(-1,1))\n    train[f'{feat}_class']=gmm.predict(train[feat].values.reshape(-1,1))\n    test[f'{feat}_class']=gmm.predict(test[feat].values.reshape(-1,1))\n    \nget_gmm_class_feature(\"BertzCT\",4)\nget_gmm_class_feature(\"Chi1\",4)\nget_gmm_class_feature(\"Chi1n\",3)\nget_gmm_class_feature(\"Chi1v\",3)\nget_gmm_class_feature(\"Chi2v\",4)\nget_gmm_class_feature(\"Chi3v\",3)\nget_gmm_class_feature(\"Chi4n\",3)\nget_gmm_class_feature(\"EState_VSA1\",2)\nget_gmm_class_feature(\"EState_VSA2\",4)\nget_gmm_class_feature(\"ExactMolWt\",3)\nget_gmm_class_feature(\"FpDensityMorgan1\",3)\nget_gmm_class_feature(\"FpDensityMorgan2\",3)\nget_gmm_class_feature(\"FpDensityMorgan3\",3)\nget_gmm_class_feature(\"HallKierAlpha\",4)\nget_gmm_class_feature(\"HeavyAtomMolWt\",3)\nget_gmm_class_feature(\"Kappa3\",1)\nget_gmm_class_feature(\"MaxAbsEStateIndex\",3)\nget_gmm_class_feature(\"MinEStateIndex\",2)\nget_gmm_class_feature(\"NumHeteroatoms\",3)\nget_gmm_class_feature(\"PEOE_VSA10\",3)\nget_gmm_class_feature(\"PEOE_VSA14\",4)\nget_gmm_class_feature(\"PEOE_VSA6\",4)\nget_gmm_class_feature(\"PEOE_VSA7\",4)\nget_gmm_class_feature(\"PEOE_VSA8\",6)\nget_gmm_class_feature(\"SMR_VSA10\",2)\nget_gmm_class_feature(\"SMR_VSA5\",3)\nget_gmm_class_feature(\"SlogP_VSA3\",3)\nget_gmm_class_feature(\"VSA_EState9\",3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num=['BertzCT', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', 'Chi2v', 'Chi3v', 'Chi4n',\n       'EState_VSA1', 'EState_VSA2', 'ExactMolWt', 'FpDensityMorgan1',\n       'FpDensityMorgan2', 'FpDensityMorgan3', 'HallKierAlpha',\n       'HeavyAtomMolWt', 'Kappa3', 'MaxAbsEStateIndex', 'MinEStateIndex',\n        'PEOE_VSA10', 'PEOE_VSA14', 'PEOE_VSA6', 'PEOE_VSA7',\n       'PEOE_VSA8', 'SMR_VSA10', 'SMR_VSA5', 'SlogP_VSA3', 'VSA_EState9']\n\ntrain['sum']=train[num].sum(axis=1)\ntrain['mean']=train[num].mean(axis=1)\ntrain['min']=train[num].min(axis=1)\ntrain['max']=train[num].max(axis=1)\ntrain['std']=train[num].std(axis=1)\ntrain['var']=train[num].var(axis=1)\n\ntest['sum']=test[num].sum(axis=1)\ntest['mean']=test[num].mean(axis=1)\ntest['min']=test[num].min(axis=1)\ntest['max']=test[num].max(axis=1)\ntest['std']=test[num].std(axis=1)\ntest['var']=test[num].var(axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Feature Engineering**","metadata":{}},{"cell_type":"code","source":"def divide_with_check(a,b):\n    result = np.where(b != 0, np.divide(a, b), 0)\n    return result\n\ndef fe(df):\n    df['BertzCT_MaxAbsEStateIndex_Ratio']= df['BertzCT'] / (df['MaxAbsEStateIndex'] + 1e-12)\n    df['BertzCT_ExactMolWt_Product']= df['BertzCT'] * df['ExactMolWt']\n    df['NumHeteroatoms_FpDensityMorgan1_Ratio']= df['NumHeteroatoms'] / (df['FpDensityMorgan1'] + 1e-12)\n    df['VSA_EState9_EState_VSA1_Ratio']= df['VSA_EState9'] / (df['EState_VSA1'] + 1e-12)\n    df['PEOE_VSA10_SMR_VSA5_Ratio']= df['PEOE_VSA10'] / (df['SMR_VSA5'] + 1e-12)\n    df['Chi1v_ExactMolWt_Product']= df['Chi1v'] * df['ExactMolWt']\n    df['Chi2v_ExactMolWt_Product']= df['Chi2v'] * df['ExactMolWt']\n    df['Chi3v_ExactMolWt_Product']= df['Chi3v'] * df['ExactMolWt']\n    df['EState_VSA1_NumHeteroatoms_Product']= df['EState_VSA1'] * df['NumHeteroatoms']\n    df['PEOE_VSA10_Chi1_Ratio']= df['PEOE_VSA10'] / (df['Chi1'] + 1e-12)\n    df['MaxAbsEStateIndex_NumHeteroatoms_Ratio']= df['MaxAbsEStateIndex'] / (df['NumHeteroatoms'] + 1e-12)\n    df['BertzCT_Chi1_Ratio']= df['BertzCT'] / (df['Chi1'] + 1e-12)\n\n    \n#     df['Enzyme_Complexity'] = df['Chi1'] + df['Chi2v'] + df['Chi3v'] + df['Chi4n']\n#     df['Molecular_Weight_Ratio'] = divide_with_check(df['ExactMolWt'] , df['HeavyAtomMolWt'])\n#     df['EState_VSA_Ratio'] = divide_with_check(df['EState_VSA1'] , df['EState_VSA2'])\n#     df['Heteroatom_Proportion'] = divide_with_check(df['NumHeteroatoms'] , (df['NumHeteroatoms'] + df['HeavyAtomMolWt']))\n#     df['frCOO_Average']= (df['fr_COO']+df['fr_COO2'])/2\n    \n#     df['Molecular_Complexity'] = df['BertzCT'] * df['ExactMolWt']\n#     df['Structural_Flexibility'] = df['Chi1'] * df['Chi2n']\n#     df['Functional_Specificity'] = df['Chi1n'] * df['Chi3v']\n#     df['Size_Related_Descriptors'] = df['ExactMolWt'] * df['FpDensityMorgan1']\n#     df['Topological_Patterns'] = df['FpDensityMorgan2'] * df['FpDensityMorgan3']\n#     df['Electronic_Structure'] = df['HallKierAlpha'] * df['MaxAbsEStateIndex']\n#     df['Atom_Weight_and_Charge'] = df['HeavyAtomMolWt'] * df['MinEStateIndex']\n#     df['Geometrical_Shape'] = df['Kappa3'] * df['NumHeteroatoms']\n#     df['Molecular_Surface_Properties'] = df['PEOE_VSA10'] * df['PEOE_VSA14']\n    \n#     df['Chemical_Diversity'] = divide_with_check(df['EState_VSA1'], df['NumHeteroatoms'])\n#     df['Functional_Group_Diversity'] = df['PEOE_VSA6'] * df['PEOE_VSA7']\n#     df['Molecular_Size'] = df['ExactMolWt'] + df['HeavyAtomMolWt']\n#     df['Electronegativity_Difference'] = df['MaxAbsEStateIndex'] - df['MinEStateIndex']\n#     df['Ring_Density'] = divide_with_check(df['NumHeteroatoms'], df['SlogP_VSA3'])\n#     df['Steric_Effects'] = divide_with_check(df['SMR_VSA5'], df['SMR_VSA10'])\n#     df['Hydrophilic_Surface'] = df['VSA_EState9'] * df['EState_VSA2']\n#     df['Molecular_Polarity'] = divide_with_check(df['PEOE_VSA8'], df['EState_VSA1'])\n    \n#     df['Ring_System_Diversity'] = divide_with_check(df['fr_COO'], df['fr_COO2'])\n#     df['Molecular_Flexibility'] = df['Chi2n'] * df['Chi3v']\n#     df['Electrostatic_Potential'] = df['EState_VSA1'] - df['EState_VSA2']\n#     df['Hydrophobicity_Index'] = divide_with_check(df['SMR_VSA10'] , df['SMR_VSA5'])\n#     df['Molecular_Conformation'] = df['Chi1'] + df['Chi4n'] - df['Chi2n']\n#     df['Functional_Group_Connectivity'] = df['PEOE_VSA14'] * df['PEOE_VSA10']\n#     df['Steric_Bulkiness'] = df['PEOE_VSA7'] - df['PEOE_VSA6']\n#     df['Aromaticity'] = df['FpDensityMorgan1'] + df['FpDensityMorgan2'] + df['FpDensityMorgan3']\n#     df['Hydrogen_Bonding_Potential'] = df['EState_VSA1'] * df['NumHeteroatoms']\n#     df['Molecular_Polarizability'] = divide_with_check(df['HallKierAlpha'] , df['Chi2v'])\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fe(train)\nfe(test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Generate features**","metadata":{}},{"cell_type":"code","source":"def generate_features(train, test, cat_cols, num_cols):\n    df = pd.concat([train, test], axis = 0, copy = False)\n    for c in cat_cols + num_cols:\n        df[f'count_{c}'] = df.groupby(c)[c].transform('count')\n    for c in cat_cols:\n        for n in num_cols:\n                df[f'mean_{n}_per_{c}'] = df.groupby(c)[n].transform('median')\n            \n    return df.iloc[:len(train),:], df.iloc[len(train):, :]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_cols = ['EC1', 'EC2']\ncols_to_drop = ['id']\n\nfeatures = [c for c in train.columns if c not in target_cols + cols_to_drop]\n\ncat_cols = ['EState_VSA2','HallKierAlpha','NumHeteroatoms','PEOE_VSA10','PEOE_VSA14','PEOE_VSA6',\n            'PEOE_VSA7','PEOE_VSA8', 'SMR_VSA10','SMR_VSA5','SlogP_VSA3','fr_COO','fr_COO2']\n\nnum_cols = [c for c in features if c not in cat_cols]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = train[features]\nY_train = train[target_cols]\nX_test = test[features]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test = generate_features(X_train, X_test, cat_cols, num_cols)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y  = Y_train\nX  = X_train","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model Training**","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import roc_auc_score\n#from sklearn.model_selection import RepeatedMultilabelStratifiedKFold\nimport numpy as np\nfrom sklearn.ensemble import GradientBoostingClassifier\n\n# XGBoost classifier parameters\nxgb_params = {'n_estimators': 100,\n              'tree_method': 'hist',\n              'max_depth': 4,\n              'reg_alpha': 0.06790740746476749,\n              'reg_lambda': 0.03393770327994609,\n              'min_child_weight': 1,\n              'gamma': 2.5705812096617772e-05,\n              'learning_rate': 0.07132617944894756,\n              'colsample_bytree': 0.11664298814833247,\n              'colsample_bynode': 0.9912092923877247,\n              'colsample_bylevel': 0.29178614622079735,\n              'subsample': 0.7395301853144935,\n              'random_state': 42\n              }\n\n# LightGBM classifier parameters\nlgbm_params = {'n_estimators': 200,\n 'boosting_type': 'gbdt',\n 'max_depth': 10,\n 'reg_alpha': 6.720380454685094,\n 'reg_lambda': 7.074828689930955e-05,\n 'min_child_samples': 15,\n 'subsample': 0.5182995486972547,\n 'learning_rate': 0.027352422199502537,\n 'colsample_bytree': 0.2257179878033366,\n 'colsample_bynode': 0.7098194984886731,\n 'random_state': 84315}\n\n# Define the classifiers\nxgb_classifier = MultiOutputClassifier(XGBClassifier(**xgb_params))\nlgbm_classifier = MultiOutputClassifier(LGBMClassifier(**lgbm_params))\n#GBC_classifier = MultiOutputClassifier(GradientBoostingClassifier(n_estimators=100))\n\n# Create the pipelines\nxgb_clf = Pipeline([('classifier', xgb_classifier)])\nlgbm_clf = Pipeline([('classifier', lgbm_classifier)])\n#GBC_clf = Pipeline([('classifier', GBC_classifier)])\n\n# Initialize variables\noof_preds_xgb = np.zeros(y.shape)\noof_preds_lgbm = np.zeros(y.shape)\n#oof_preds_GBC = np.zeros(y.shape)\n\ntest_preds_xgb = np.zeros((test.shape[0], y.shape[1]))\ntest_preds_lgbm = np.zeros((test.shape[0], y.shape[1]))\n#test_preds_GBC = np.zeros((test.shape[0], y.shape[1]))\n\noof_losses_xgb = []\noof_losses_lgbm = []\n#oof_losses_GBC = []\n\nn_splits = 10\nkf = RepeatedMultilabelStratifiedKFold(n_splits=n_splits, n_repeats=1, random_state=42)\ntrain_losses_xgb = []\ntrain_losses_lgbm = []\ntrain_losses_GBC = []\n\nover_train=[]\nover_valid=[]\n# Loop over folds\nfor fn, (trn_idx, val_idx) in enumerate(kf.split(X, y)):\n    print('Starting fold:', fn)\n    X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n    y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n\n    # Train and predict with XGBoost classifier\n    xgb_clf.fit(X_train, y_train)\n    train_preds_xgb = xgb_clf.predict_proba(X_train)\n    train_preds_xgb = np.array(train_preds_xgb)[:, :, 1].T\n    #train_loss_xgb = roc_auc_score(np.ravel(y_train), np.ravel(train_preds_xgb))\n    #train_losses_xgb.append(train_loss_xgb)\n\n    val_preds_xgb = xgb_clf.predict_proba(X_val)\n    val_preds_xgb = np.array(val_preds_xgb)[:, :, 1].T\n    oof_preds_xgb[val_idx] = val_preds_xgb\n    loss_xgb = roc_auc_score(np.ravel(y_val), np.ravel(val_preds_xgb))\n    oof_losses_xgb.append(loss_xgb)\n    preds_xgb = xgb_clf.predict_proba(X_test)\n    preds_xgb = np.array(preds_xgb)[:, :, 1].T\n    test_preds_xgb += preds_xgb / n_splits\n\n    \n\n    # Train and predict with LightGBM classifier\n    lgbm_clf.fit(X_train, y_train)\n    train_preds_lgbm = lgbm_clf.predict_proba(X_train)\n    train_preds_lgbm = np.array(train_preds_lgbm)[:, :, 1].T\n    #train_loss_lgbm = roc_auc_score(np.ravel(y_train), np.ravel(train_preds_lgbm))\n    #train_losses_lgbm.append(train_loss_lgbm)\n\n    val_preds_lgbm = lgbm_clf.predict_proba(X_val)\n    val_preds_lgbm = np.array(val_preds_lgbm)[:, :, 1].T\n    oof_preds_lgbm[val_idx] = val_preds_lgbm\n\n    loss_lgbm = roc_auc_score(np.ravel(y_val), np.ravel(val_preds_lgbm))\n    oof_losses_lgbm.append(loss_lgbm)\n    preds_lgbm = lgbm_clf.predict_proba(X_test)\n    preds_lgbm = np.array(preds_lgbm)[:, :, 1].T\n    test_preds_lgbm += preds_lgbm / n_splits\n    \"\"\"\n    # Train and predict with GBC classifier\n    GBC_clf.fit(X_train, y_train)\n    train_preds_GBC = GBC_clf.predict_proba(X_train)\n    train_preds_GBC = np.array(train_preds_GBC)[:, :, 1].T\n    #train_loss_lgbm = roc_auc_score(np.ravel(y_train), np.ravel(train_preds_lgbm))\n    #train_losses_lgbm.append(train_loss_lgbm)\n\n    val_preds_GBC = GBC_clf.predict_proba(X_val)\n    val_preds_GBC = np.array(val_preds_GBC)[:, :, 1].T\n    oof_preds_GBC[val_idx] = val_preds_GBC\n\n    loss_GBC = roc_auc_score(np.ravel(y_val), np.ravel(val_preds_lgbm))\n    oof_losses_GBC.append(loss_GBC)\n    preds_GBC = GBC_clf.predict_proba(X_test)\n    preds_GBC = np.array(preds_GBC)[:, :, 1].T\n    test_preds_GBC += preds_GBC / n_splits\n    \"\"\"\n    \n    overall_train_preds = (train_preds_xgb+train_preds_lgbm)/2\n    overall_train_loss = roc_auc_score(np.ravel(y_train), np.ravel(overall_train_preds))\n    overall_valid_preds = (val_preds_xgb+val_preds_lgbm)/2\n    overall_valid_loss = roc_auc_score(np.ravel(y_val), np.ravel(overall_valid_preds))\n    over_train.append(overall_train_loss)\n    over_valid.append(overall_valid_loss)\n    print(\"overall_train\",overall_train_loss)\n    print(\"overall_valid\",overall_valid_loss)\n\nprint(\"over_train\",np.mean(over_train))\nprint(\"over_valid\",np.mean(over_valid))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Submission**","metadata":{}},{"cell_type":"code","source":"sample_submission.iloc[:,1:] = (test_preds_xgb+test_preds_lgbm)/2","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.to_csv(\"submission.csv\",index=False)","metadata":{},"execution_count":null,"outputs":[]}]}